{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation Engine \u2014 Training Notebook\n",
    "\n",
    "This notebook trains an SVD-based collaborative filtering model on the MovieLens ml-latest-small dataset.\n",
    "\n",
    "**Steps:**\n",
    "1. Dataset overview & EDA\n",
    "2. Baseline predictor (BaselineOnly ALS)\n",
    "3. SVD with default parameters\n",
    "4. Hyperparameter tuning (GridSearchCV)\n",
    "5. Results summary & export\n",
    "\n",
    "**Target:** ~22% MAE reduction vs baseline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, pickle, time, os\n",
    "from surprise import Dataset, Reader, SVD, BaselineOnly\n",
    "from surprise.model_selection import cross_validate, GridSearchCV"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load & Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load processed ratings\n",
    "ratings = pd.read_csv('../data/processed/all_ratings.csv')\n",
    "movies = pd.read_csv('../data/processed/movies_metadata.csv')\n",
    "\n",
    "print(f'Ratings: {len(ratings):,}')\n",
    "print(f'Users:   {ratings[\"userId\"].nunique()}')\n",
    "print(f'Movies:  {ratings[\"movieId\"].nunique()}')\n",
    "print(f'Sparsity: {1 - len(ratings) / (ratings[\"userId\"].nunique() * ratings[\"movieId\"].nunique()):.2%}')\n",
    "print()\n",
    "ratings.describe()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Rating distribution\n",
    "print('Rating Distribution:')\n",
    "print(ratings['rating'].value_counts().sort_index())\n",
    "print(f'\\nMean rating: {ratings[\"rating\"].mean():.3f}')\n",
    "print(f'Median rating: {ratings[\"rating\"].median()}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Surprise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "print('Surprise dataset loaded.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Predictor\n",
    "\n",
    "Using Surprise's `BaselineOnly` with ALS optimization. This models user and item biases only (no latent factors)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "baseline = BaselineOnly(bsl_options={'method': 'als', 'n_epochs': 10})\n",
    "baseline_results = cross_validate(baseline, data, measures=['MAE', 'RMSE'], cv=5, verbose=True)\n",
    "\n",
    "baseline_mae = baseline_results['test_mae'].mean()\n",
    "baseline_rmse = baseline_results['test_rmse'].mean()\n",
    "print(f'\\nBaseline MAE:  {baseline_mae:.4f}')\n",
    "print(f'Baseline RMSE: {baseline_rmse:.4f}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SVD with Default Parameters\n",
    "\n",
    "SVD decomposes the rating matrix R \u2248 P \u00d7 Q^T where P and Q are low-rank user/item factor matrices."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "svd_default = SVD()\n",
    "svd_results = cross_validate(svd_default, data, measures=['MAE', 'RMSE'], cv=5, verbose=True)\n",
    "\n",
    "default_mae = svd_results['test_mae'].mean()\n",
    "default_rmse = svd_results['test_rmse'].mean()\n",
    "print(f'\\nDefault SVD MAE:  {default_mae:.4f}')\n",
    "print(f'Default SVD RMSE: {default_rmse:.4f}')\n",
    "print(f'Improvement vs Baseline: {(baseline_mae - default_mae) / baseline_mae * 100:.1f}%')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Tuning (GridSearchCV)\n",
    "\n",
    "Searching over n_factors, n_epochs, learning rate, and regularization."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    'n_factors': [50, 100, 150, 200],\n",
    "    'n_epochs': [20, 30, 40],\n",
    "    'lr_all': [0.002, 0.005, 0.01],\n",
    "    'reg_all': [0.02, 0.05, 0.1],\n",
    "}\n",
    "\n",
    "total = 1\n",
    "for v in param_grid.values(): total *= len(v)\n",
    "print(f'Searching {total} combinations (3-fold CV)...')\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['mae', 'rmse'], cv=3, n_jobs=-1)\n",
    "gs.fit(data)\n",
    "\n",
    "tuned_mae = gs.best_score['mae']\n",
    "tuned_rmse = gs.best_score['rmse']\n",
    "best_params = gs.best_params['mae']\n",
    "\n",
    "print(f'\\nBest MAE:    {tuned_mae:.4f}')\n",
    "print(f'Best RMSE:   {tuned_rmse:.4f}')\n",
    "print(f'Best params: {json.dumps(best_params, indent=2)}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "improvement = (baseline_mae - tuned_mae) / baseline_mae * 100\n",
    "\n",
    "print('=' * 50)\n",
    "print('FINAL RESULTS')\n",
    "print('=' * 50)\n",
    "print(f'{\"Baseline MAE (ALS)\":<30} {baseline_mae:.4f}')\n",
    "print(f'{\"Default SVD MAE\":<30} {default_mae:.4f}')\n",
    "print(f'{\"Tuned SVD MAE\":<30} {tuned_mae:.4f}')\n",
    "print(f'{\"MAE reduction vs Baseline\":<30} {improvement:.1f}%')\n",
    "print()\n",
    "print('Best Hyperparameters:')\n",
    "for k, v in best_params.items():\n",
    "    print(f'  {k}: {v}')\n",
    "\n",
    "if improvement >= 20:\n",
    "    print(f'\\n\u2713 TARGET MET: {improvement:.1f}% MAE reduction')\n",
    "else:\n",
    "    print(f'\\n\u26a0 Achieved {improvement:.1f}% (target ~22%)')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Final Model & Export"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train on full dataset with best params\n",
    "final_svd = SVD(**best_params)\n",
    "trainset = data.build_full_trainset()\n",
    "final_svd.fit(trainset)\n",
    "\n",
    "# Save\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "with open('../models/svd_model.pkl', 'wb') as f:\n",
    "    pickle.dump({'model': final_svd, 'trainset': trainset}, f)\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    'baseline_mae': round(baseline_mae, 4),\n",
    "    'default_svd_mae': round(default_mae, 4),\n",
    "    'tuned_svd_mae': round(tuned_mae, 4),\n",
    "    'mae_reduction_pct': round(improvement, 1),\n",
    "    'best_params': best_params,\n",
    "    'dataset': 'MovieLens ml-latest-small',\n",
    "    'algorithm': 'SVD (Matrix Factorization)',\n",
    "    'library': 'Surprise',\n",
    "}\n",
    "with open('../models/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print('Model and metrics saved successfully.')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}